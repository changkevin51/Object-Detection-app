{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import gdown\n",
    "import argparse\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "with HiddenPrints():\n",
    "    # Prepare data\n",
    "    DATA_ROOT = 'C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\'\n",
    "\n",
    "    os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "    !pip -q install streamlit\n",
    "    !pip -q install pyngrok\n",
    "\n",
    "    from pyngrok import ngrok\n",
    "    import streamlit\n",
    "\n",
    "    # # image_url = 'https://drive.google.com/uc?id=12ZpZ5H0kJIkWk6y4ktGfqR5OTKofL7qw'\n",
    "    # # image_path = os.path.join(DATA_ROOT, 'image.jpg')\n",
    "    # # gdown.download(image_url, image_path, True)\n",
    "    # !wget -O /content/data/image.jpg \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/image.jpg\"\n",
    "\n",
    "    # # image2_url = 'https://drive.google.com/uc?id=1_WpFbGEuS2r19UeP6wekbcF0kb-0nH18'\n",
    "    # # image2_path = os.path.join(DATA_ROOT, 'image2.jpg')\n",
    "    # # gdown.download(image2_url, image2_path, True)\n",
    "    # !wget -O /content/data/image2.jpg \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/image2.jpg\"\n",
    "\n",
    "    # # video_url = 'https://drive.google.com/uc?id=1xFGjpzhZVYtNor9hJevvxysGESZJIMDz'\n",
    "    # # video_path = os.path.join(DATA_ROOT, 'video1.mp4')\n",
    "    # # gdown.download(video_url, video_path, True)\n",
    "    # !wget -O /content/data/video1.mp4 \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/6.mp4\"\n",
    "\n",
    "    # # model_url = 'https://drive.google.com/uc?id=19XKJWMKDfDlag2MR8ofjwvxhtr9BxqqN'\n",
    "    # # model_path = os.path.join(DATA_ROOT, 'yolo_weights.h5')\n",
    "    # # gdown.download(model_url, model_path, True)\n",
    "    # !wget -O /content/data/yolo_weights.h5 \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/yolo.h5\"\n",
    "\n",
    "\n",
    "\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "    return float(intersect) / union\n",
    "\n",
    "def preprocess_input(image_pil, net_h, net_w):\n",
    "    image = np.asarray(image_pil)\n",
    "    new_h, new_w, _ = image.shape\n",
    "    # print(\"net:\", net_h, net_w)\n",
    "    # print(\"old:\",new_h, new_w)\n",
    "    # determine the new size of the image\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)/new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)/new_h\n",
    "        new_h = net_h\n",
    "    new_w = int(new_w)\n",
    "    new_h = int(new_h)\n",
    "    # print(\"new:\",int(new_h), int(new_w))\n",
    "    # resize the image to the new size\n",
    "    #resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
    "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
    "\n",
    "    # embed the image into the standard letter box\n",
    "    # print(\"dims:\",int((net_h-new_h)//2), int((net_h+new_h)//2), int((net_w-new_w)//2), int((net_w+new_w)//2))\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "    # print(new_image.shape)\n",
    "\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
    "    netout_all = deepcopy(netout_)\n",
    "    boxes_all = []\n",
    "    for i in range(len(netout_all)):\n",
    "      netout = netout_all[i][0]\n",
    "      anchors = anchors_[i]\n",
    "\n",
    "      grid_h, grid_w = netout.shape[:2]\n",
    "      nb_box = 3\n",
    "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "      nb_class = netout.shape[-1] - 5\n",
    "\n",
    "      boxes = []\n",
    "\n",
    "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "      for i in range(grid_h*grid_w):\n",
    "          row = i // grid_w\n",
    "          col = i % grid_w\n",
    "\n",
    "          for b in range(nb_box):\n",
    "              # 4th element is objectness score\n",
    "              objectness = netout[row][col][b][4]\n",
    "              #objectness = netout[..., :4]\n",
    "              # last elements are class probabilities\n",
    "              classes = netout[row][col][b][5:]\n",
    "\n",
    "              if((classes <= obj_thresh).all()): continue\n",
    "\n",
    "              # first 4 elements are x, y, w, and h\n",
    "              x, y, w, h = netout[row][col][b][:4]\n",
    "\n",
    "              x = (col + x) / grid_w # center position, unit: image width\n",
    "              y = (row + y) / grid_h # center position, unit: image height\n",
    "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
    "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
    "\n",
    "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "              boxes.append(box)\n",
    "\n",
    "      boxes_all += boxes\n",
    "\n",
    "    # Correct boxes\n",
    "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    return boxes_all\n",
    "\n",
    "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    return boxes\n",
    "\n",
    "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if len(boxes) > 0:\n",
    "        num_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for c in range(num_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        label = -1\n",
    "\n",
    "        for i in range(num_class):\n",
    "            if box.classes[i] > obj_thresh:\n",
    "                label = i\n",
    "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
    "                box.label = label\n",
    "                box.score = box.classes[i]\n",
    "                new_boxes.append(box)\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import colorsys\n",
    "\n",
    "def draw_boxes(image_, boxes, labels):\n",
    "    image = image_.copy()\n",
    "    image_w, image_h = image.size\n",
    "    font = ImageFont.load_default()\n",
    "    # font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
    "    #                 size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
    "    thickness = (image_w + image_h) // 300\n",
    "\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [(x / len(labels), 1., 1.)\n",
    "                  for x in range(len(labels))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "    for i, box in reversed(list(enumerate(boxes))):\n",
    "        c = box.get_label()\n",
    "        predicted_class = labels[c]\n",
    "        score = box.get_score()\n",
    "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textbbox((0,0),label, font)\n",
    "        label_size = (label_size[2], label_size[3])\n",
    "\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "            fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
    "        del draw\n",
    "    return image\n",
    "\n",
    "def launch_website():\n",
    "  try:\n",
    "    if ngrok.get_tunnels():\n",
    "      ngrok.kill()\n",
    "    tunnel = ngrok.connect()\n",
    "\n",
    "    print(\"Click this link to try your web app:\")\n",
    "    print(tunnel.public_url)\n",
    "\n",
    "    !streamlit run --server.port 80 app.py >/dev/null # Connect to the URL through Port 80 (>/dev/null hides outputs)\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "    ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.20 (main, Oct  3 2024, 07:38:01) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "port = \"5000\"\n",
    "# Define Flask routes\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return \"Hello from Colab!\"\n",
    "\n",
    "# Start the Flask server in a new thread\n",
    "threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Press CTRL+C to quit"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "\n",
    "anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]\n",
    "\n",
    "DATA_ROOT = 'C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\'\n",
    "\n",
    "model_path = os.path.join(DATA_ROOT, 'yolo.h5')\n",
    "\n",
    "darknet = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "    return float(intersect) / union\n",
    "\n",
    "def preprocess_input(image_pil, net_h, net_w):\n",
    "    image = np.asarray(image_pil)\n",
    "    # Remove the alpha channel if it exists\n",
    "    if image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    new_h, new_w, _ = image.shape\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)/new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)/new_h\n",
    "        new_h = net_h\n",
    "\n",
    "    new_w = int(new_w)\n",
    "    new_h = int(new_h)\n",
    "\n",
    "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
    "\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
    "    netout_all = deepcopy(netout_)\n",
    "    boxes_all = []\n",
    "    for i in range(len(netout_all)):\n",
    "      netout = netout_all[i][0]\n",
    "      anchors = anchors_[i]\n",
    "\n",
    "      grid_h, grid_w = netout.shape[:2]\n",
    "      nb_box = 3\n",
    "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "      nb_class = netout.shape[-1] - 5\n",
    "\n",
    "      boxes = []\n",
    "\n",
    "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "      for i in range(grid_h*grid_w):\n",
    "          row = i // grid_w\n",
    "          col = i % grid_w\n",
    "\n",
    "          for b in range(nb_box):\n",
    "              # 4th element is objectness score\n",
    "              objectness = netout[row][col][b][4]\n",
    "              #objectness = netout[..., :4]\n",
    "              # last elements are class probabilities\n",
    "              classes = netout[row][col][b][5:]\n",
    "\n",
    "              if((classes <= obj_thresh).all()): continue\n",
    "\n",
    "              # first 4 elements are x, y, w, and h\n",
    "              x, y, w, h = netout[row][col][b][:4]\n",
    "\n",
    "              x = (col + x) / grid_w # center position, unit: image width\n",
    "              y = (row + y) / grid_h # center position, unit: image height\n",
    "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
    "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
    "\n",
    "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "              boxes.append(box)\n",
    "\n",
    "      boxes_all += boxes\n",
    "\n",
    "    # Correct boxes\n",
    "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    return boxes_all\n",
    "\n",
    "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    return boxes\n",
    "\n",
    "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if len(boxes) > 0:\n",
    "        num_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for c in range(num_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        label = -1\n",
    "\n",
    "        for i in range(num_class):\n",
    "            if box.classes[i] > obj_thresh:\n",
    "                label = i\n",
    "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
    "                box.label = label\n",
    "                box.score = box.classes[i]\n",
    "                new_boxes.append(box)\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import colorsys\n",
    "\n",
    "# def draw_boxes(image_, boxes, labels):\n",
    "#     image = image_.copy()\n",
    "#     image_w, image_h = image.size\n",
    "#     font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
    "#                     size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
    "#     thickness = (image_w + image_h) // 300\n",
    "\n",
    "#     # Generate colors for drawing bounding boxes.\n",
    "#     hsv_tuples = [(x / len(labels), 1., 1.)\n",
    "#                   for x in range(len(labels))]\n",
    "#     colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "#     colors = list(\n",
    "#         map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "#     np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "#     np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "#     np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "def draw_boxes(image_, boxes, labels):\n",
    "    image = image_.copy()\n",
    "    image_w, image_h = image.size\n",
    "    font = ImageFont.load_default()  # Use default PIL font\n",
    "    thickness = (image_w + image_h) // 300\n",
    "\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [(x / len(labels), 1., 1.) for x in range(len(labels))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors)\n",
    "    )\n",
    "    \n",
    "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "    for i, box in reversed(list(enumerate(boxes))):\n",
    "        c = box.get_label()\n",
    "        predicted_class = labels[c]\n",
    "        score = box.get_score()\n",
    "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textbbox((0,0),label, font)\n",
    "        label_size = (label_size[2], label_size[3])\n",
    "\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "            fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
    "        del draw\n",
    "    return image\n",
    "\n",
    "def detect_image(image_pil, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
    "\n",
    "  # Preprocessing\n",
    "  image_w, image_h = image_pil.size\n",
    "  new_image = preprocess_input(image_pil, net_h, net_w)\n",
    "\n",
    "  # DarkNet\n",
    "  yolo_outputs = darknet.predict(new_image)\n",
    "\n",
    "  # Decode the output of the network\n",
    "  boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
    "\n",
    "  # Suppress non-maximal boxes\n",
    "  boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
    "\n",
    "  # Draw bounding boxes on the image using labels\n",
    "  image_detect = draw_boxes(image_pil, boxes, labels)\n",
    "\n",
    "  return image_detect\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Object Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "import tempfile\n",
    "import subprocess\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]\n",
    "\n",
    "DATA_ROOT = 'C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\'\n",
    "\n",
    "model_path = os.path.join(DATA_ROOT, 'yolo.h5')\n",
    "\n",
    "darknet = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    if union == 0:\n",
    "      return 0\n",
    "\n",
    "    return float(intersect) / union\n",
    "\n",
    "def preprocess_input(image_pil, net_h, net_w):\n",
    "    image = np.asarray(image_pil)\n",
    "    # Remove the alpha channel if it exists\n",
    "    if image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    new_h, new_w, _ = image.shape\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)/new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)/new_h\n",
    "        new_h = net_h\n",
    "\n",
    "    new_w = int(new_w)\n",
    "    new_h = int(new_h)\n",
    "\n",
    "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
    "\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
    "    netout_all = deepcopy(netout_)\n",
    "    boxes_all = []\n",
    "    for i in range(len(netout_all)):\n",
    "      netout = netout_all[i][0]\n",
    "      anchors = anchors_[i]\n",
    "\n",
    "      grid_h, grid_w = netout.shape[:2]\n",
    "      nb_box = 3\n",
    "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "      nb_class = netout.shape[-1] - 5\n",
    "\n",
    "      boxes = []\n",
    "\n",
    "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "      for i in range(grid_h*grid_w):\n",
    "          row = i // grid_w\n",
    "          col = i % grid_w\n",
    "\n",
    "          for b in range(nb_box):\n",
    "              # 4th element is objectness score\n",
    "              objectness = netout[row][col][b][4]\n",
    "              #objectness = netout[..., :4]\n",
    "              # last elements are class probabilities\n",
    "              classes = netout[row][col][b][5:]\n",
    "\n",
    "              if((classes <= obj_thresh).all()): continue\n",
    "\n",
    "              # first 4 elements are x, y, w, and h\n",
    "              x, y, w, h = netout[row][col][b][:4]\n",
    "\n",
    "              x = (col + x) / grid_w # center position, unit: image width\n",
    "              y = (row + y) / grid_h # center position, unit: image height\n",
    "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
    "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
    "\n",
    "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "              boxes.append(box)\n",
    "\n",
    "      boxes_all += boxes\n",
    "\n",
    "    # Correct boxes\n",
    "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    return boxes_all\n",
    "\n",
    "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    return boxes\n",
    "\n",
    "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
    "    boxes = deepcopy(boxes_)\n",
    "    if len(boxes) > 0:\n",
    "        num_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for c in range(num_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "    new_boxes = []\n",
    "    for box in boxes:\n",
    "        label = -1\n",
    "\n",
    "        for i in range(num_class):\n",
    "            if box.classes[i] > obj_thresh:\n",
    "                label = i\n",
    "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
    "                box.label = label\n",
    "                box.score = box.classes[i]\n",
    "                new_boxes.append(box)\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import colorsys\n",
    "\n",
    "def draw_boxes(image_, boxes, labels):\n",
    "    image = image_.copy()\n",
    "    image_w, image_h = image.size\n",
    "    \n",
    "    # Load the new font (Open Sans ExtraBold)\n",
    "    try:\n",
    "        font_path = \"C:\\\\Users\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\.conda\\\\fonts\\\\open-fonts\\\\OpenSans-SemiBold.ttf\"\n",
    "        font = ImageFont.truetype(font=font_path, size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
    "    except IOError:\n",
    "        print(\"Font not found. Using default font.\")\n",
    "        font = ImageFont.load_default()  # Fallback to default if font not found\n",
    "    \n",
    "    thickness = (image_w + image_h) // 300\n",
    "\n",
    "    # Generate colors for drawing bounding boxes\n",
    "    hsv_tuples = [(x / len(labels), 1., 1.) for x in range(len(labels))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "    np.random.seed(10101)  # Fixed seed for consistent colors across runs\n",
    "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes\n",
    "    np.random.seed(None)  # Reset seed to default\n",
    "\n",
    "    for i, box in reversed(list(enumerate(boxes))):\n",
    "        c = box.get_label()\n",
    "        predicted_class = labels[c]\n",
    "        score = box.get_score()\n",
    "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # Calculate label size with the chosen font\n",
    "        label_size = draw.textbbox((0, 0), label, font)\n",
    "        label_size = (label_size[2], label_size[3])\n",
    "\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # Draw bounding boxes and labels\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "\n",
    "        del draw\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def detect_image(image_pil, obj_thresh=0.4, nms_thresh=0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
    "    # Preprocessing\n",
    "    image_w, image_h = image_pil.size\n",
    "    new_image = preprocess_input(image_pil, net_h, net_w)\n",
    "\n",
    "    # DarkNet Prediction\n",
    "    yolo_outputs = darknet.predict(new_image)\n",
    "\n",
    "    # Decode the output of the network\n",
    "    boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    # Suppress non-maximal boxes\n",
    "    boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
    "\n",
    "    # If no boxes are detected, return a message\n",
    "    if not boxes:\n",
    "        return \"No objects related to transportation detected\"\n",
    "\n",
    "    # Draw bounding boxes on the image using labels\n",
    "    image_detect = draw_boxes(image_pil, boxes, labels)\n",
    "\n",
    "    return image_detect\n",
    "\n",
    "def detect_video(video_path, output_path, obj_thresh=0.4, nms_thresh=0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "\n",
    "    video_FourCC = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "    video_size = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                  int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
    "\n",
    "    num_frame = 0\n",
    "    progress_text = \"Processing video frames. Please wait.\"\n",
    "    my_bar = st.progress(0, text=progress_text)\n",
    "    start_time = time.time()\n",
    "    while vid.isOpened():\n",
    "        ret, frame = vid.read()\n",
    "        num_frame += 1\n",
    "        print(\"=== Frame {} ===\".format(num_frame))\n",
    "        if ret:\n",
    "            ### YOUR CODE HERE\n",
    "            image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            result_pil = detect_image(image_pil, obj_thresh, nms_thresh, darknet, net_h, net_w, anchors, labels)\n",
    "            new_frame = cv2.cvtColor(np.asarray(result_pil), cv2.COLOR_RGB2BGR)\n",
    "            ### END CODE\n",
    "\n",
    "            out.write(new_frame)\n",
    "\n",
    "            if time.time() - start_time >= 1:\n",
    "                progress = int((num_frame / total_frames) * 100)\n",
    "                my_bar.progress(progress, text=f\"{progress}% completed: Detecting frame {num_frame}/{total_frames}\")\n",
    "                start_time = time.time()  # Reset the timer\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    my_bar.progress(100, text=\"Processing complete: All frames processed.\")\n",
    "    time.sleep(1)\n",
    "    my_bar.empty()\n",
    "\n",
    "    vid.release()\n",
    "    out.release()\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file generated: C:\\Users\\chang\\Documents\\Python Projects\\Object_Detection\\example_video.mp4\n",
      "Converted file generated: C:\\Users\\chang\\Documents\\Python Projects\\Object_Detection\\example_video_converted.mp4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "original_path = \"C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\video1.mp4\"\n",
    "original_output_path = \"C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\example_video.mp4\"\n",
    "command = f\"ffmpeg -y -i {original_path} -vcodec libx264 {original_output_path}\"\n",
    "subprocess.call(command, shell=True)\n",
    "\n",
    "example_video = 'C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\video1_detected.mp4'\n",
    "output_path = \"C:\\\\Users\\\\chang\\\\Documents\\\\Python_Projects\\\\Object_Detection\\\\example_video_converted.mp4\"\n",
    "command = f\"ffmpeg -y -i {example_video} -vcodec libx264 {output_path}\"\n",
    "subprocess.call(command, shell=True)\n",
    "\n",
    "print(\"Output file generated:\", original_output_path)\n",
    "print(\"Converted file generated:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "import time\n",
    "import io\n",
    "import subprocess\n",
    "import cv2\n",
    "\n",
    "# Initialize session state for settings\n",
    "if 'obj_thresh' not in st.session_state:\n",
    "    st.session_state['obj_thresh'] = 0.4\n",
    "if 'nms_thresh' not in st.session_state:\n",
    "    st.session_state['nms_thresh'] = 0.45\n",
    "if 'image_format' not in st.session_state:\n",
    "    st.session_state['image_format'] = 'PNG'\n",
    "\n",
    "# Function to reset settings to default\n",
    "def reset_settings():\n",
    "    st.session_state['obj_thresh'] = 0.4\n",
    "    st.session_state['nms_thresh'] = 0.45\n",
    "    st.session_state['image_format'] = 'PNG'\n",
    "    st.rerun()  # Reload the entire app\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    @import url('https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;600&display=swap');\n",
    "\n",
    "    html, body, [data-testid=\"stAppViewContainer\"], [data-testid=\"stApp\"] {\n",
    "        height: 100%;\n",
    "        margin: 0;\n",
    "    }\n",
    "    [data-testid=\"stApp\"] {\n",
    "        display: flex;\n",
    "        flex-direction: column;\n",
    "    }\n",
    "    .main-content {\n",
    "        flex: 1 0 auto;\n",
    "    }\n",
    "    .title {\n",
    "        color: #c6ccd5;\n",
    "        font-size: 3em;\n",
    "        font-family: 'IBM Plex Sans', sans-serif;\n",
    "        text-align: center;\n",
    "        margin-bottom: 0.2em;\n",
    "        font-weight: 600;\n",
    "    }\n",
    "    .subheader {\n",
    "        color: #9aa1aa;\n",
    "        font-size: 1.5em;\n",
    "        font-family: 'IBM Plex Sans', sans-serif;\n",
    "        text-align: center;\n",
    "        margin-bottom: 2em;\n",
    "        font-weight: 400;\n",
    "    }\n",
    "    .footer {\n",
    "        flex-shrink: 0;\n",
    "        color: #999999;\n",
    "        text-align: center;\n",
    "        margin-top: 2em;\n",
    "        font-size: 0.8em;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown('<div class=\"title\">Object Detection Project</div>', unsafe_allow_html=True)\n",
    "st.markdown('<div class=\"subheader\">Precision Object Detection for Transportation</div>', unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar settings\n",
    "st.sidebar.header(\"Settings\")\n",
    "\n",
    "# Object Threshold\n",
    "st.sidebar.subheader(\"Object Threshold\")\n",
    "st.sidebar.write(\"The Object Threshold controls the confidence level required to detect an object. \"\n",
    "                 \"A higher value means fewer but more confident detections, while a lower value means more detections but with less confidence.\")\n",
    "st.session_state['obj_thresh'] = st.sidebar.slider('Adjust Object Threshold', 0.0, 1.0, st.session_state['obj_thresh'])\n",
    "\n",
    "# Non-max Suppression Threshold\n",
    "st.sidebar.subheader(\"Non-max Suppression Threshold\")\n",
    "st.sidebar.write(\"The Non-max Suppression (NMS) Threshold controls the overlap allowed between detected objects. \"\n",
    "                 \"A lower value means stricter overlap rules, which reduces duplicate detections, while a higher value allows more overlap.\")\n",
    "st.session_state['nms_thresh'] = st.sidebar.slider('Adjust NMS Threshold', 0.0, 1.0, st.session_state['nms_thresh'])\n",
    "\n",
    "# Image Format\n",
    "st.sidebar.subheader(\"Output Image Format\")\n",
    "st.session_state['image_format'] = st.sidebar.selectbox('Choose Format', ('PNG', 'JPEG'), index=['PNG', 'JPEG'].index(st.session_state['image_format']))\n",
    "\n",
    "# Reset button\n",
    "if st.sidebar.button('Reset'):\n",
    "    reset_settings()\n",
    "\n",
    "# File uploader\n",
    "uploaded_file = st.file_uploader(\"Choose an image or video...\", type=[\"jpg\", \"png\", \"mp4\"])\n",
    "\n",
    "# Try an example button\n",
    "example_image_path = \"preview16.jpg\"\n",
    "example_video_converted = 'example_video_converted.mp4'\n",
    "\n",
    "# Function to load example files as BytesIO objects\n",
    "def load_example_as_bytesio(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return io.BytesIO(f.read())\n",
    "\n",
    "# Load example files into BytesIO objects\n",
    "example_image = load_example_as_bytesio(example_image_path)\n",
    "\n",
    "# Buttons for example image and video\n",
    "if st.button('Try an Example Image', type=\"primary\"):\n",
    "    uploaded_file = example_image\n",
    "    uploaded_file.name = \"example_image.jpg\"\n",
    "\n",
    "# EXAMPLE VIDEO\n",
    "#########################\n",
    "if 'try_example' not in st.session_state:\n",
    "    st.session_state.try_example = False\n",
    "if 'play_video' not in st.session_state:\n",
    "    st.session_state.play_video = False\n",
    "if 'run_detection' not in st.session_state:\n",
    "    st.session_state.run_detection = False\n",
    "\n",
    "# Function to reset states when 'Try an Example Video' is clicked\n",
    "def reset_states():\n",
    "    st.session_state.play_video = False\n",
    "    st.session_state.run_detection = False\n",
    "def reset_all_states():\n",
    "    st.session_state.try_example = False\n",
    "    st.session_state.play_video = False\n",
    "    st.session_state.run_detection = False\n",
    "\n",
    "# Handle 'Try an Example Video' button\n",
    "if st.button('Try an Example Video', type=\"primary\"):\n",
    "    st.session_state.try_example = True\n",
    "    reset_states()\n",
    "\n",
    "# try:\n",
    "if st.session_state.try_example:\n",
    "    # Handle 'Play Pre-detected Video' button\n",
    "    if st.button('Play Pre-detected Video'):\n",
    "        st.session_state.play_video = True\n",
    "        st.session_state.run_detection = False  # Ensure the other option is not active\n",
    "\n",
    "    # Handle 'Run Detection on Video' button\n",
    "    if st.button('Run Detection on Video'):\n",
    "        st.session_state.run_detection = True\n",
    "        st.session_state.play_video = False  # Ensure the other option is not active\n",
    "\n",
    "    # Show videos based on the button clicked\n",
    "    if st.session_state.play_video:\n",
    "        st.write(\"Example video:\")\n",
    "        st.video(\"example_video.mp4\")\n",
    "        st.write(\"\")\n",
    "        st.write(\"Example video detected:\")\n",
    "        st.video(\"example_video_converted.mp4\")\n",
    "        reset_all_states()\n",
    "\n",
    "    if st.session_state.run_detection:\n",
    "        st.video(\"example_video.mp4\")\n",
    "        st.write(\"Processing video with object detection...\")\n",
    "        video_path = \"example_video.mp4\"\n",
    "        output_path = \"detected_video.mp4\"\n",
    "\n",
    "        detect_video(video_path, output_path, obj_thresh=st.session_state['obj_thresh'], nms_thresh=st.session_state['nms_thresh'])\n",
    "\n",
    "        output_path1 = \"detected_video1.mp4\"\n",
    "        command = f\"ffmpeg -y -i {output_path} -vcodec libx264 {output_path1}\"\n",
    "        subprocess.call(command, shell=True)\n",
    "        st.toast(' Done!', icon='')\n",
    "        st.write(\"\")\n",
    "        st.write(\"Detected video:\")\n",
    "        st.video(output_path1)\n",
    "\n",
    "        with open(output_path1, \"rb\") as file:\n",
    "            st.download_button(\n",
    "                label=\" Download Video [MP4]\",\n",
    "                data=file,\n",
    "                file_name=\"detected_video.mp4\",\n",
    "                mime=\"video/mp4\"\n",
    "            )\n",
    "        reset_all_states()\n",
    "############################\n",
    "if uploaded_file is not None:\n",
    "    file_extension = uploaded_file.name.split('.')[-1].lower()\n",
    "\n",
    "    if file_extension in [\"jpg\", \"png\"]:\n",
    "        image = Image.open(uploaded_file)\n",
    "        st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
    "        st.write(\"\")\n",
    "\n",
    "        with st.status(\"Detecting...\"):\n",
    "            st.write(\" Processing image...\")\n",
    "            time.sleep(0.5)\n",
    "            st.write(\" Localizing objects...\")\n",
    "            detected_image = detect_image(image, obj_thresh=st.session_state['obj_thresh'], nms_thresh=st.session_state['nms_thresh'])\n",
    "            st.write(\" Labelling...\")\n",
    "            time.sleep(1)\n",
    "        st.toast(' Done!', icon='')\n",
    "        if type(detected_image) == str:\n",
    "            st.write(\"\")\n",
    "            if st.session_state['obj_thresh'] >= 0.6:\n",
    "                st.write(\"No objects detected. Try lowering the Object Threshold.\")\n",
    "            else:\n",
    "                st.write(detected_image)\n",
    "        else:\n",
    "            st.image(detected_image, caption='Detected Image.', use_column_width=True)\n",
    "\n",
    "            # Convert the image to a BytesIO object and provide a download button\n",
    "            buffer = io.BytesIO()\n",
    "            detected_image.save(buffer, format=st.session_state['image_format'])\n",
    "            buffer.seek(0)\n",
    "\n",
    "            st.download_button(\n",
    "                label=f\" Download image [High Quality - {st.session_state['image_format']}]\",\n",
    "                data=buffer,\n",
    "                file_name=f\"detected_image.{st.session_state['image_format'].lower()}\",\n",
    "                mime=f\"image/{st.session_state['image_format'].lower()}\"\n",
    "            )\n",
    "\n",
    "    elif file_extension in [\"mp4\"]:\n",
    "        with open(\"video.mp4\", \"wb\") as f:\n",
    "            f.write(uploaded_file.read())\n",
    "        example_video = \"video1.mp4\"\n",
    "        if uploaded_file != example_video:\n",
    "            video_path = \"video.mp4\"\n",
    "        st.write(\"Uploaded video:\")\n",
    "        st.video(uploaded_file)\n",
    "        output_path = \"detected_video.mp4\"\n",
    "\n",
    "        detect_video(video_path, output_path, obj_thresh=st.session_state['obj_thresh'], nms_thresh=st.session_state['nms_thresh'])\n",
    "\n",
    "        output_path1 = \"detected_video1.mp4\"\n",
    "        command = f\"ffmpeg -y -i {output_path} -vcodec libx264 {output_path1}\"\n",
    "        subprocess.call(command, shell=True)\n",
    "        st.toast(' Done!', icon='')\n",
    "        st.write(\"\")\n",
    "        st.write(\"Detected video:\")\n",
    "        st.video(output_path1)\n",
    "\n",
    "        with open(output_path1, \"rb\") as file:\n",
    "            st.download_button(\n",
    "                label=\" Download Video [MP4]\",\n",
    "                data=file,\n",
    "                file_name=\"detected_video.mp4\",\n",
    "                mime=\"video/mp4\"\n",
    "            )\n",
    "\n",
    "for i in range(7):\n",
    "    st.write(\"\")\n",
    "st.markdown('<div class=\"footer\">This app uses YOLOv3 to detect objects in images and videos</div>', unsafe_allow_html=True)\n",
    "st.write(\"\")\n",
    "st.markdown('<div class=\"footer\">A project by Kevin Chang</div>', unsafe_allow_html=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
